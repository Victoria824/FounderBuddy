"""Generate decision node for Special Report Agent."""

import logging

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.runnables import RunnableConfig

from core.llm import get_model
from core.logging_config import get_logger
from ..models import SpecialReportState, ChatAgentOutput
from ..enums import RouterDirective

logger = get_logger(__name__)


async def generate_decision_node(state: SpecialReportState, config: RunnableConfig) -> SpecialReportState:
    """Generate structured decision output based on conversation analysis."""
    current_section = state.get('current_section')
    logger.info(f"Generate decision node - Section: {current_section}")
    
    # Get the reply generated by the previous node
    current_reply = state.get("current_reply", "")
    
    # Build conversation context for decision analysis
    messages = []
    
    # Add system prompt for decision analysis
    decision_prompt = f"""You are analyzing a conversation between an AI assistant and a user for structured decision making.

CONTEXT:
- Current section: {current_section.value if current_section else "unknown"}
- The AI has already generated this reply: "{current_reply}"

Your job is to analyze the conversation and determine:
1. Router directive (stay/next/modify:section_id)
2. Whether the AI is requesting satisfaction rating
3. User satisfaction feedback (if provided)
4. Whether user is satisfied (if determinable)
5. Section update content (if AI provided summary)

DECISION RULES:
- Use "stay" if continuing to collect information or user needs to respond
- Use "next" if section is complete and user is satisfied
- Use "modify:section_id" if user requests to jump to different section
- Only set is_requesting_rating=true if the AI reply explicitly asks for satisfaction rating
- Extract section_update if the AI provided a summary of collected information
- Interpret user satisfaction from natural language responses

The AI's reply was: {current_reply}"""
    
    messages.append(SystemMessage(content=decision_prompt))
    
    # Add recent conversation history for context
    conversation_messages = state.get("messages", [])[-6:]  # Last 6 messages for context
    for msg in conversation_messages:
        if isinstance(msg, HumanMessage):
            messages.append(SystemMessage(content=f"USER: {msg.content}"))
        elif isinstance(msg, AIMessage):
            messages.append(SystemMessage(content=f"AI: {msg.content}"))
    
    try:
        # Use structured output to get decision
        llm = get_model()
        structured_llm = llm.with_structured_output(ChatAgentOutput, method="function_calling")
        
        # Use non-streaming config to prevent internal analysis from appearing in user stream
        decision_config = RunnableConfig(
            configurable={"stream": False},
            tags=["decision_analysis", "internal"]
        )
        
        logger.info("=== CALLING DECISION LLM WITH STRUCTURED OUTPUT ===")
        decision_output = await structured_llm.ainvoke(messages, config=decision_config)
        
        # Override the reply field with our generated reply
        decision_output.reply = current_reply
        
        logger.info("=== DECISION_OUTPUT_DEBUG ===")
        logger.info(f"üéØ Router directive: {decision_output.router_directive}")
        logger.info(f"üìù User satisfaction feedback: {decision_output.user_satisfaction_feedback}")
        logger.info(f"üòä Is satisfied: {decision_output.is_satisfied}")
        logger.info(f"üíæ Section update provided: {bool(decision_output.section_update)}")
        
        # Apply business logic corrections
        if decision_output.is_satisfied is not None and decision_output.is_satisfied:
            # If user is satisfied, ensure we proceed to next section
            if decision_output.router_directive == "stay":
                logger.info("User satisfied but directive was 'stay' - correcting to 'next'")
                decision_output.router_directive = "next"
        
        # Set the is_awaiting_rating flag based on the structured output
        if decision_output.is_requesting_rating:
            # CRITICAL VALIDATION: If requesting rating, should have section_update
            if not decision_output.section_update:
                logger.warning("AI requested rating but provided no section_update - may need content")
            
            state["is_awaiting_rating"] = True
            logger.info(f"State updated: is_awaiting_rating set to {decision_output.is_requesting_rating}")
        else:
            state["is_awaiting_rating"] = False

        # Store the complete decision output
        state["agent_output"] = decision_output

        # Set router directive for the router node
        state["router_directive"] = decision_output.router_directive

        logger.info(f"DEBUG_DECISION_NODE: Decision generated successfully: {decision_output.router_directive}")

    except Exception as e:
        logger.error(f"Failed to get structured decision from LLM: {e}")
        
        # Create fallback decision
        default_output = ChatAgentOutput(
            reply=current_reply,
            router_directive="stay",
            is_requesting_rating=False,
            user_satisfaction_feedback=None,
            is_satisfied=None,
            section_update=None,
        )
        state["agent_output"] = default_output
        state["router_directive"] = "stay"
        state["awaiting_user_input"] = True
    
    return state